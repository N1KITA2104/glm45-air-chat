# AI Chat Platform

This repository contains a full-stack chat application that integrates Z.AI's **GLM 4.5 Air Free** model via the OpenRouter API. It delivers a contextual chat experience with FastAPI + PostgreSQL on the backend and a React (Vite) frontend powered by `llm-ui` for smooth LLM output rendering.

> ğŸ’¡ Default model: [`z-ai/glm-4.5-air:free`](https://openrouter.ai/z-ai/glm-4.5-air/api?utm_source=openai)

---

## Features

- ğŸ” JWT authentication with registration, login, and profile editing
- ğŸ’¬ Chat management (create, rename, delete) with contextual memory
- ğŸ§  OpenRouter integration for GLM 4.5 Air Free responses
- ğŸ§© `llm-ui` rendering for markdown/code-friendly assistant replies
- ğŸ“± Responsive React UI with chat sidebar, history, and streaming-friendly output
- ğŸ§ª Basic health-check test suite for the FastAPI service

---

## Prerequisites

- **Node.js** â‰¥ 18
- **Python** â‰¥ 3.11
- **PostgreSQL** â‰¥ 14
- OpenRouter account + API key (model: GLM 4.5 Air Free)

---

## Backend Setup (FastAPI)

```bash
cd backend
python -m venv .venv
.venv\Scripts\activate    # Windows
# source .venv/bin/activate  # macOS/Linux

pip install -r requirements.txt
cp .env.example .env
```

Update `.env` with your database connection string and `OPEN_ROUTER_API_KEY`.

**Note:** By default, CORS is configured to allow requests from `http://localhost:5173` (dev) and `http://localhost:4173` (preview). To add more origins, set `BACKEND_CORS_ORIGINS` in `.env` as a comma-separated list.

Run migrations/DDL by starting the app once (tables auto-create):

```bash
uvicorn app.main:app --reload
```

---

## Frontend Setup (React + Vite)

```bash
cd frontend
npm install
cp .env.example .env
# if backend runs elsewhere, update VITE_API_BASE_URL
npm run dev
```

Open http://localhost:5173 in your browser.

---

## Running Tests

```bash
cd backend
pytest
```

(Uses an on-disk SQLite database for isolation.)

---

## API Overview

- `POST /auth/register` â€“ create new user
- `POST /auth/login` â€“ authenticate and receive JWT
- `GET /profile/me` â€“ authenticated user profile
- `PATCH /profile/me` â€“ update display name
- `GET /chats` â€“ list chats for user
- `POST /chats` â€“ create chat (optional custom title/model)
- `PATCH /chats/{chat_id}` â€“ rename chat
- `DELETE /chats/{chat_id}` â€“ delete chat
- `GET /chats/{chat_id}/messages` â€“ list messages
- `POST /chats/{chat_id}/messages` â€“ send prompt & receive model reply

---

## Development Tips

- Configure `BACKEND_CORS_ORIGINS` for additional frontends (comma-separated).
- Adjust `OPENROUTER_TEMPERATURE` or `SYSTEM_PROMPT` in `.env` to tune assistant behaviour.
- `llm-ui` is ready for streaming; the current implementation renders completed responses but is open for future streaming upgrades.

---

## License

MIT Â© 2025 AI Chat Platform contributors.

